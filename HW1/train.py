# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GCJlXjpmrzsrP17QW7Sq1bkW9k-0j0bV
"""

! pip install pytorch_model_summary
! pip install tqdm

cd "/content/drive/MyDrive/Colab Notebooks/CV HW1 Q5"

! ls

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from pytorch_model_summary import summary
from torchvision.models import vgg
from torchvision.datasets import CIFAR10
from torchvision import transforms
from tqdm import tqdm, trange
import matplotlib.pyplot as plt

# hyper-parameter
BATCH_SIZE = 64
EPOCH = 50
LR = 1e-3

# Dataset from torchvision
to_tensor = transforms.ToTensor()
train_set = CIFAR10("Dataset", train=True, transform=to_tensor)
test_set = CIFAR10("Dataset", train=False, transform=to_tensor)

# data loader
train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)
test_loader = DataLoader(test_set, batch_size=BATCH_SIZE * 2)

# model from torchvision
class VGG_w_cls(nn.Module):
    def __init__(self):
        super(VGG_w_cls, self).__init__()
        self.m = nn.Sequential(
            vgg.vgg16(),
            nn.Linear(1000, 10)
        )

    def forward(self, x):
        return self.m(x)

model = VGG_w_cls()
print(model)
# print(summary(vgg.vgg16(), torch.zeros((1, 3, 32, 32))))


# optimizer and loss function
optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)
loss_func = nn.CrossEntropyLoss()
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model = model.to(device)

print(device)

# train
epoch_loss = []
model.train()
for epoch in trange(EPOCH):
    running_loss = 0.0
    for data in train_loader:
        imgs, labels = [t.to(device) for t in data]

        optimizer.zero_grad()

        outputs = model(imgs)

        loss = loss_func(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    running_loss /= len(train_loader.dataset)
    print(running_loss)
    epoch_loss += [running_loss]
    torch.save(model.state_dict(), f"model/e_{epoch}")

# test
model = VGG_w_cls()
epoch_acc = []
for epoch in trange(28):
    model.load_state_dict(torch.load(f"model/e_{epoch}", map_location=torch.device(device)))
    model = model.to(device)

    model.eval()
    correct = 0
    with torch.no_grad():
        for data in test_loader:
            imgs, labels = [t.to(device) for t in data]

            outputs = model(imgs)

            outputs = torch.argmax(outputs, axis = 1)
            correct += (outputs == labels).sum().item()

        acc = correct / len(test_loader.dataset)
            
        print(acc)
        epoch_acc += [acc]

import pickle
with open('epoch_loss.pkl', 'wb') as f:
    pickle.dump(epoch_loss, f)
with open('epoch_acc.pkl', 'wb') as f:
    pickle.dump(epoch_acc, f)